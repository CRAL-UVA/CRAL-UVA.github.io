---
title: Research
permalink: /research/
---

<!-- ### About us -->
Our longstanding goal is for robots to navigate among humans, like humans. Think last mile delivery robots and service robots operating fully autonomously in public spaces like airports, restaurants, and hospitals. This includes developing algorithms and systems that can do planning-aware perception, that can reason about the behavior of humans using local information only, and that can plan trajectories that are not just provably safe, but also agile, smooth, and efficient.

### Research

<iframe width="360" height="180" src="https://www.youtube.com/embed/t4tkCCIGXRU?autoplay=1&mute=1&loop=1&playlist=t4tkCCIGXRU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><iframe width="360" height="180" src="https://www.youtube.com/embed/0Zjmm31b1fI?autoplay=1&mute=1&loop=1&playlist=0Zjmm31b1fI" title="Rethinking Social Robot Navigation: Leveraging the Best of Two Worlds" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<br>

#### *Agile, but Safe* Multi-Robot Systems
Humans are safe, but at the same time, move with grace and agility in order to be efficient and comfortable. For example, a more impatient individual will overtake a slow-moving group in front and squeeze through narrow gaps even if it means means light contact with other people or objects. Robots today sacrifice efficiency for safety, and cannot be fully deployed in complex human environments. <br>

We work on developing multi-robot algorithms and systems with generalizability, liveness, agility, and safety guarantees in fully decentralized settings in unstructured environments. We routinely work in the sub-areas of optimal control and multi-agent reinforcement learning, and testing out our ideas both in simulation as well as on real physical robots.

#### *Next-Generation Mind-Body Controlled* Human-Robot Interaction

We are building a next-generation paradigm for human-robot interaction where humans can interact with robots seamlessly and perform complex tasks via mind and body gestures.

At the same time, we are designing algorithms for robots to understand human intent. As humans, we always infer other people's intent without them ever having to verbally indicate so. For instance, we can tell a person's state of mind, simply from their style of walking, their gestures, their facial expressions, etc. Can we leverage these non-verbal cues for social robot navigation?


#### Autonomous Driving *in Dense, Heterogeneous, and Chaotic Environments*

Over the past decade, we have made immense progress in autonomous driving in developed nations like U.S.A, Europe, UK, etc. But we are still far from achieving the same success in developing nations like India, where the traffic is far denser, far more heterogeneous, and far more chaotic. Our research focuses on developing autonomous driving and ADAS for traffic in these regions. 